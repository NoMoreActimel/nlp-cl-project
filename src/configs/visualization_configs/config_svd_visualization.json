{
  "model": {
    "type": "T5SVDLoRA",
    "args": {
      "t5_config": {
        "model_name": "t5-base",
        "cache_dir": "cache/",
        "max_length": 256
      },
      "svd_lora_config": {
        "rank": 4,
        "target_layers": ["q", "k", "v", "o", "wi", "wo"]
      }
    }
  },
  "tokenizer_name": "T5Tokenizer",
  "tokenizer_from_pretrained": "google-t5/t5-base",
  "resume": "saved/models/T5_CL_summarization/0127_235759/checkpoint-epoch1.pth",
  "layer_names": [
    "model.decoder.block.5.layer.0.SelfAttention.q.lora",
    "model.decoder.block.5.layer.0.SelfAttention.k.lora",
    "model.decoder.block.5.layer.0.SelfAttention.v.lora",
    "model.decoder.block.5.layer.0.SelfAttention.o.lora",
    "model.decoder.block.5.layer.1.EncDecAttention.q.lora",
    "model.decoder.block.5.layer.1.EncDecAttention.k.lora",
    "model.decoder.block.5.layer.1.EncDecAttention.v.lora",
    "model.decoder.block.5.layer.1.EncDecAttention.o.lora",
    "model.decoder.block.5.layer.2.DenseReluDense.wi.lora",
    "model.decoder.block.5.layer.2.DenseReluDense.wo.lora",
    "model.encoder.block.5.layer.0.SelfAttention.q.lora",
    "model.encoder.block.5.layer.0.SelfAttention.k.lora",
    "model.encoder.block.5.layer.0.SelfAttention.v.lora",
    "model.encoder.block.5.layer.0.SelfAttention.o.lora",
    "model.encoder.block.5.layer.1.EncDecAttention.q.lora",
    "model.encoder.block.5.layer.1.EncDecAttention.k.lora",
    "model.encoder.block.5.layer.1.EncDecAttention.v.lora",
    "model.encoder.block.5.layer.1.EncDecAttention.o.lora",
    "model.encoder.block.5.layer.2.DenseReluDense.wi.lora",
    "model.encoder.block.5.layer.2.DenseReluDense.wo.lora",
    "model.decoder.block.11.layer.0.SelfAttention.q.lora",
    "model.decoder.block.11.layer.0.SelfAttention.k.lora",
    "model.decoder.block.11.layer.0.SelfAttention.v.lora",
    "model.decoder.block.11.layer.0.SelfAttention.o.lora",
    "model.decoder.block.11.layer.1.EncDecAttention.q.lora",
    "model.decoder.block.11.layer.1.EncDecAttention.k.lora",
    "model.decoder.block.11.layer.1.EncDecAttention.v.lora",
    "model.decoder.block.11.layer.1.EncDecAttention.o.lora",
    "model.decoder.block.11.layer.2.DenseReluDense.wi.lora",
    "model.decoder.block.11.layer.2.DenseReluDense.wo.lora",
    "model.encoder.block.11.layer.0.SelfAttention.q.lora",
    "model.encoder.block.11.layer.0.SelfAttention.k.lora",
    "model.encoder.block.11.layer.0.SelfAttention.v.lora",
    "model.encoder.block.11.layer.0.SelfAttention.o.lora",
    "model.encoder.block.11.layer.1.EncDecAttention.q.lora",
    "model.encoder.block.11.layer.1.EncDecAttention.k.lora",
    "model.encoder.block.11.layer.1.EncDecAttention.v.lora",
    "model.encoder.block.11.layer.1.EncDecAttention.o.lora",
    "model.encoder.block.11.layer.2.DenseReluDense.wi.lora",
    "model.encoder.block.11.layer.2.DenseReluDense.wo.lora"
  ]
}
