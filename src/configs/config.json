{
  "name": "decoder_on_tinystories",
  "n_gpu": 1,
  "preprocessing": {},
  "model": {
      "type": "T5forSummarization",
      "args": {
        "model_name": "t5-base",
        "cache_dir": "/content/nlp-cl-project/cache/"
      }
  },
  "data": {
    "train": {
      "batch_size": 256,
      "num_workers": 5,
      "use_mixed_dataset": true,
      "mixed_dataset": {
        "type": "MixedSequentialDataset",
        "args": {
          "sequential_mixing_rate": 0.1
        }
      },
      "datasets": [
        {
          "type": "OriginalDataset",
          "args": {
            "dataset_dir": "/content/nlp-cl-project/summarization-data/cnndm",
            "tokenizer_name": ["T5Tokenizer", "google-t5/t5-small"],
            "split": "train",
            "max_length": 512
          }
        },
        {
          "type": "OriginalDataset",
          "args": {
            "dataset_dir": "/content/nlp-cl-project/summarization-data/wikihow",
            "tokenizer_name": ["T5Tokenizer", "google-t5/t5-small"],
            "split": "train",
            "max_length": 512
          }
        },
        {
          "type": "OriginalDataset",
          "args": {
            "dataset_dir": "/content/nlp-cl-project/summarization-data/xsum",
            "tokenizer_name": ["T5Tokenizer", "google-t5/t5-small"],
            "split": "train",
            "max_length": 512
          }
        }
      ]
    },
    "val": {
      "batch_size": 256,
      "num_workers": 5,
      "inference_on_evaluation": true,
      "inference_indices": [24, 2, 22],
      "inference_temperatures": [0.5, 1.0, 2.0],
      "use_mixed_dataset": true,
      "mixed_dataset": {
        "type": "MixedSequentialDataset",
        "args": {
          "sequential_mixing_rate": 0.1
        }
      },
      "datasets": [
        {
          "type": "OriginalDataset",
          "args": {
            "dataset_dir": "/content/nlp-cl-project/summarization-data/cnndm",
            "tokenizer_name": ["T5Tokenizer", "google-t5/t5-small"],
            "split": "valid",
            "max_length": 512
          }
        },
        {
          "type": "OriginalDataset",
          "args": {
            "dataset_dir": "/content/nlp-cl-project/summarization-data/wikihow",
            "tokenizer_name": ["T5Tokenizer", "google-t5/t5-small"],
            "split": "valid",
            "max_length": 512
          }
        },
        {
          "type": "OriginalDataset",
          "args": {
            "dataset_dir": "/content/nlp-cl-project/summarization-data/xsum",
            "tokenizer_name": ["T5Tokenizer", "google-t5/t5-small"],
            "split": "valid",
            "max_length": 512
          }
        }
      ]
    }
  },
  "optimizer": {
    "type": "AdamW",
    "args": {
      "lr": 5e-1,
      "betas": [0.9, 0.95],
      "weight_decay": 1e-5
    }
  },
  "metrics": [
    {
      "type": "RougeMetric",
      "args": {}
    }
  ],
  "lr_scheduler": {
    "type": "ExponentialLR",
    "args": {
      "gamma": 1.0
    }
  },
  "loss": {
    "type": "CrossEntropyLoss",
    "args": {}
  },
  "trainer": {
    "epochs": 1000,
    "save_dir": "saved/",
    "save_period": 5,
    "verbosity": 2,
    "monitor": "min loss",
    "early_stop": 100,
    "visualize": "wandb",
    "wandb_project": "dl-hse-bhw-Tiny-Stories",
    "wandb_run_name": "12L-8h-512-Decoder, sp-word",
    "len_epoch": 1000,
    "grad_norm_clip": 1.0
  }
}